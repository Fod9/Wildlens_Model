{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T11:56:55.499701Z",
     "start_time": "2025-06-28T11:56:54.476787Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "device = \"cuda\" if tf.config.list_physical_devices(\"GPU\") else \"cpu\"\n",
    "\n",
    "# Set memory growth for GPU\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Load data"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 13:56:54.585342: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-28 13:56:54.593310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-28 13:56:54.602159: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-28 13:56:54.604940: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-28 13:56:54.612588: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-28 13:56:55.094350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/spokay/miniconda3/envs/yolo_end/lib/python3.12/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "2025-06-28 13:56:55.498099: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2025-06-28 13:56:55.498123: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:135] retrieving CUDA diagnostic information for host: 2a01cb0001104f00845b1dbbc3600f10.ipv6.abo.wanadoo.fr\n",
      "2025-06-28 13:56:55.498129: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:142] hostname: 2a01cb0001104f00845b1dbbc3600f10.ipv6.abo.wanadoo.fr\n",
      "2025-06-28 13:56:55.498244: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:166] libcuda reported version is: 570.153.2\n",
      "2025-06-28 13:56:55.498260: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  570.153.02  Release Build  (dvs-builder@U22-A23-20-3)  Tue May 13 16:34:58 UTC 2025\n",
      "GCC version:  gcc version 15.1.1 20250521 (Red Hat 15.1.1-2) (GCC) \n",
      "\"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T21:03:30.356453Z",
     "start_time": "2025-06-26T21:03:30.256274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2514 files belonging to 18 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 23:03:30.296194: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleLoadData(&module, data)' failed with 'CUDA_ERROR_INVALID_PTX'\n",
      "\n",
      "2025-06-26 23:03:30.296219: W tensorflow/compiler/mlir/tools/kernel_gen/tf_gpu_runtime_wrappers.cc:40] 'cuModuleGetFunction(&function, module, kernel_name)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "\n",
      "2025-06-26 23:03:30.296227: W tensorflow/core/framework/op_kernel.cc:1829] INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n",
      "2025-06-26 23:03:30.296234: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INTERNAL: 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE'\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "{{function_node __wrapped__Equal_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Equal] name: ",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mInternalError\u001B[39m                             Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m train_ds = keras.preprocessing.image_dataset_from_directory(\n\u001B[32m      2\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m../../data/OpenAnimalTracks_spokay/cropped_imgs/train\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      3\u001B[39m     image_size=(\u001B[32m224\u001B[39m, \u001B[32m224\u001B[39m),\n\u001B[32m      4\u001B[39m     batch_size=\u001B[32m16\u001B[39m,\n\u001B[32m      5\u001B[39m )\n\u001B[32m      6\u001B[39m test_ds = keras.preprocessing.image_dataset_from_directory(\n\u001B[32m      7\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m../../data/OpenAnimalTracks_spokay/cropped_imgs/test\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m      8\u001B[39m     image_size=(\u001B[32m224\u001B[39m, \u001B[32m224\u001B[39m),\n\u001B[32m      9\u001B[39m     batch_size=\u001B[32m16\u001B[39m,\n\u001B[32m     10\u001B[39m )\n\u001B[32m     11\u001B[39m val_ds = keras.preprocessing.image_dataset_from_directory(\n\u001B[32m     12\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33m../../data/OpenAnimalTracks_spokay/cropped_imgs/val\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     13\u001B[39m     image_size=(\u001B[32m224\u001B[39m, \u001B[32m224\u001B[39m),\n\u001B[32m     14\u001B[39m     batch_size=\u001B[32m16\u001B[39m,\n\u001B[32m     15\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/yolo_end/lib/python3.12/site-packages/keras/src/utils/image_dataset_utils.py:334\u001B[39m, in \u001B[36mimage_dataset_from_directory\u001B[39m\u001B[34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001B[39m\n\u001B[32m    328\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m image_paths:\n\u001B[32m    329\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    330\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mNo images found in directory \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirectory\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    331\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAllowed formats: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mALLOWLIST_FORMATS\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    332\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m334\u001B[39m dataset = paths_and_labels_to_dataset(\n\u001B[32m    335\u001B[39m     image_paths=image_paths,\n\u001B[32m    336\u001B[39m     image_size=image_size,\n\u001B[32m    337\u001B[39m     num_channels=num_channels,\n\u001B[32m    338\u001B[39m     labels=labels,\n\u001B[32m    339\u001B[39m     label_mode=label_mode,\n\u001B[32m    340\u001B[39m     num_classes=\u001B[38;5;28mlen\u001B[39m(class_names) \u001B[38;5;28;01mif\u001B[39;00m class_names \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m0\u001B[39m,\n\u001B[32m    341\u001B[39m     interpolation=interpolation,\n\u001B[32m    342\u001B[39m     crop_to_aspect_ratio=crop_to_aspect_ratio,\n\u001B[32m    343\u001B[39m     pad_to_aspect_ratio=pad_to_aspect_ratio,\n\u001B[32m    344\u001B[39m     data_format=data_format,\n\u001B[32m    345\u001B[39m     shuffle=shuffle,\n\u001B[32m    346\u001B[39m     shuffle_buffer_size=shuffle_buffer_size,\n\u001B[32m    347\u001B[39m     seed=seed,\n\u001B[32m    348\u001B[39m )\n\u001B[32m    350\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m batch_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    351\u001B[39m     dataset = dataset.batch(batch_size)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/yolo_end/lib/python3.12/site-packages/keras/src/utils/image_dataset_utils.py:389\u001B[39m, in \u001B[36mpaths_and_labels_to_dataset\u001B[39m\u001B[34m(image_paths, image_size, num_channels, labels, label_mode, num_classes, interpolation, data_format, crop_to_aspect_ratio, pad_to_aspect_ratio, shuffle, shuffle_buffer_size, seed)\u001B[39m\n\u001B[32m    386\u001B[39m     ds = path_ds\n\u001B[32m    388\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[32m--> \u001B[39m\u001B[32m389\u001B[39m     ds = ds.shuffle(buffer_size=shuffle_buffer_size \u001B[38;5;129;01mor\u001B[39;00m \u001B[32m1024\u001B[39m, seed=seed)\n\u001B[32m    391\u001B[39m args = (\n\u001B[32m    392\u001B[39m     image_size,\n\u001B[32m    393\u001B[39m     num_channels,\n\u001B[32m   (...)\u001B[39m\u001B[32m    397\u001B[39m     pad_to_aspect_ratio,\n\u001B[32m    398\u001B[39m )\n\u001B[32m    399\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m label_mode:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/yolo_end/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:1510\u001B[39m, in \u001B[36mDatasetV2.shuffle\u001B[39m\u001B[34m(self, buffer_size, seed, reshuffle_each_iteration, name)\u001B[39m\n\u001B[32m   1419\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mshuffle\u001B[39m(\n\u001B[32m   1420\u001B[39m     \u001B[38;5;28mself\u001B[39m, buffer_size, seed=\u001B[38;5;28;01mNone\u001B[39;00m, reshuffle_each_iteration=\u001B[38;5;28;01mTrue\u001B[39;00m, name=\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1421\u001B[39m ) -> \u001B[33m\"\u001B[39m\u001B[33mDatasetV2\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1422\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Randomly shuffles the elements of this dataset.\u001B[39;00m\n\u001B[32m   1423\u001B[39m \n\u001B[32m   1424\u001B[39m \u001B[33;03m  This dataset fills a buffer with `buffer_size` elements, then randomly\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1508\u001B[39m \u001B[33;03m    A new `Dataset` with the transformation applied as described above.\u001B[39;00m\n\u001B[32m   1509\u001B[39m \u001B[33;03m  \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1510\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m shuffle_op._shuffle(  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[32m   1511\u001B[39m       \u001B[38;5;28mself\u001B[39m, buffer_size, seed, reshuffle_each_iteration, name=name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/yolo_end/lib/python3.12/site-packages/tensorflow/python/data/ops/shuffle_op.py:32\u001B[39m, in \u001B[36m_shuffle\u001B[39m\u001B[34m(input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_shuffle\u001B[39m(  \u001B[38;5;66;03m# pylint: disable=unused-private-name\u001B[39;00m\n\u001B[32m     26\u001B[39m     input_dataset,\n\u001B[32m     27\u001B[39m     buffer_size,\n\u001B[32m   (...)\u001B[39m\u001B[32m     30\u001B[39m     name=\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m     31\u001B[39m ):\n\u001B[32m---> \u001B[39m\u001B[32m32\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m _ShuffleDataset(\n\u001B[32m     33\u001B[39m       input_dataset, buffer_size, seed, reshuffle_each_iteration, name=name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/yolo_end/lib/python3.12/site-packages/tensorflow/python/data/ops/shuffle_op.py:51\u001B[39m, in \u001B[36m_ShuffleDataset.__init__\u001B[39m\u001B[34m(self, input_dataset, buffer_size, seed, reshuffle_each_iteration, name)\u001B[39m\n\u001B[32m     48\u001B[39m \u001B[38;5;28mself\u001B[39m._input_dataset = input_dataset\n\u001B[32m     49\u001B[39m \u001B[38;5;28mself\u001B[39m._buffer_size = ops.convert_to_tensor(\n\u001B[32m     50\u001B[39m     buffer_size, dtype=dtypes.int64, name=\u001B[33m\"\u001B[39m\u001B[33mbuffer_size\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m \u001B[38;5;28mself\u001B[39m._seed, \u001B[38;5;28mself\u001B[39m._seed2 = random_seed.get_seed(seed)\n\u001B[32m     52\u001B[39m \u001B[38;5;28mself\u001B[39m._reshuffle_each_iteration = reshuffle_each_iteration\n\u001B[32m     53\u001B[39m \u001B[38;5;28mself\u001B[39m._name = name\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/yolo_end/lib/python3.12/site-packages/tensorflow/python/data/util/random_seed.py:50\u001B[39m, in \u001B[36mget_seed\u001B[39m\u001B[34m(seed)\u001B[39m\n\u001B[32m     46\u001B[39m   \u001B[38;5;28;01mwith\u001B[39;00m ops.name_scope(\u001B[33m\"\u001B[39m\u001B[33mseed2\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[32m     47\u001B[39m     seed2 = ops.convert_to_tensor(seed2, dtype=dtypes.int64)\n\u001B[32m     48\u001B[39m     seed2 = array_ops.where_v2(\n\u001B[32m     49\u001B[39m         math_ops.logical_and(\n\u001B[32m---> \u001B[39m\u001B[32m50\u001B[39m             math_ops.equal(seed, \u001B[32m0\u001B[39m), math_ops.equal(seed2, \u001B[32m0\u001B[39m)),\n\u001B[32m     51\u001B[39m         constant_op.constant(\u001B[32m2\u001B[39m**\u001B[32m31\u001B[39m - \u001B[32m1\u001B[39m, dtype=dtypes.int64),\n\u001B[32m     52\u001B[39m         seed2,\n\u001B[32m     53\u001B[39m         name=scope)\n\u001B[32m     54\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m seed, seed2\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/yolo_end/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    151\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    152\u001B[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m--> \u001B[39m\u001B[32m153\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    154\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    155\u001B[39m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/yolo_end/lib/python3.12/site-packages/tensorflow/python/framework/ops.py:6002\u001B[39m, in \u001B[36mraise_from_not_ok_status\u001B[39m\u001B[34m(e, name)\u001B[39m\n\u001B[32m   6000\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mraise_from_not_ok_status\u001B[39m(e, name) -> NoReturn:\n\u001B[32m   6001\u001B[39m   e.message += (\u001B[33m\"\u001B[39m\u001B[33m name: \u001B[39m\u001B[33m\"\u001B[39m + \u001B[38;5;28mstr\u001B[39m(name \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m))\n\u001B[32m-> \u001B[39m\u001B[32m6002\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m core._status_to_exception(e) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[31mInternalError\u001B[39m: {{function_node __wrapped__Equal_device_/job:localhost/replica:0/task:0/device:GPU:0}} 'cuLaunchKernel(function, gridX, gridY, gridZ, blockX, blockY, blockZ, 0, reinterpret_cast<CUstream>(stream), params, nullptr)' failed with 'CUDA_ERROR_INVALID_HANDLE' [Op:Equal] name: "
     ]
    }
   ],
   "source": [
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../data/OpenAnimalTracks_spokay/cropped_imgs/train\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=16,\n",
    ")\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../data/OpenAnimalTracks_spokay/cropped_imgs/test\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=16,\n",
    ")\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../data/OpenAnimalTracks_spokay/cropped_imgs/val\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = keras.applications.MobileNetV3Small(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    ")\n",
    "\n",
    "# Initially freeze the base model\n",
    "mobilenet.trainable = False\n",
    "\n",
    "# Data augmentation\n",
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip(\"horizontal\"),\n",
    "    keras.layers.RandomRotation(0.1),\n",
    "    keras.layers.RandomZoom(0.1),\n",
    "    keras.layers.RandomContrast(0.1),\n",
    "])\n",
    "\n",
    "# Build the complete model\n",
    "model = keras.Sequential([\n",
    "    data_augmentation,\n",
    "    mobilenet,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(18, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(optimizer=\"adamax\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_ds, epochs=50, validation_data=val_ds, callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)])\n",
    "\n",
    "# Save the model\n",
    "model.save(\"mobilenet_oat.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilnet = keras.models.load_model(\"mobilenet_oat.keras\")\n",
    "mobilenet.trainable = True\n",
    "\n",
    "fine_tune_at = len(mobilenet.layers) - 20\n",
    "\n",
    "for layer in mobilenet.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5), \n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds, callbacks=[keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../data/dataset_no_oat_downsample_spokay\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(0.8 * len(real_ds))\n",
    "val_size = len(real_ds) - train_size\n",
    "\n",
    "real_train_ds = real_ds.take(train_size)\n",
    "real_val_ds = real_ds.skip(train_size)\n",
    "\n",
    "print(f\"Dataset d'entraînement: {train_size} batches\")\n",
    "print(f\"Dataset de validation: {val_size} batches\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Début du fine-tuning...\")\n",
    "\n",
    "\n",
    "history = mobilnet.fit(\n",
    "    real_train_ds,\n",
    "    epochs=60,\n",
    "    validation_data=real_val_ds,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-7)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "finetuned_model.save(\"mobilenet_finetuned_with_no_oat.keras\")\n",
    "print(\"Modèle fine-tuné sauvegardé sous 'mobilenet_finetuned.keras'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluation du modèle fine-tuné\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Afficher les courbes d'apprentissage\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Perte du modèle')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Perte')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Précision du modèle')\n",
    "plt.xlabel('Époque')\n",
    "plt.ylabel('Précision')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Évaluer sur l'ensemble de validation\n",
    "val_loss, val_accuracy = finetuned_model.evaluate(real_val_ds)\n",
    "print(f\"Précision finale sur les données de validation: {val_accuracy:.4f}\")\n",
    "print(f\"Perte finale sur les données de validation: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

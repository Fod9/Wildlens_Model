{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFViTForImageClassification: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing TFViTForImageClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFViTForImageClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFViTForImageClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFViTForImageClassification for predictions without further training.\n",
      "Some weights of TFViTForImageClassification were not initialized from the model checkpoint are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape (1000, 768) in the checkpoint and (768, 13) in the model instantiated\n",
      "- classifier.bias: found shape (1000,) in the checkpoint and (13,) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFViTForImageClassification, ViTImageProcessor\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "def create_vit_huggingface(num_classes=13):\n",
    "    model = TFViTForImageClassification.from_pretrained(\n",
    "        'google/vit-base-patch16-224',\n",
    "        num_labels=num_classes,\n",
    "        ignore_mismatched_sizes=True \n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model: TFViTForImageClassification = create_vit_huggingface(num_classes=13)\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2514 files belonging to 18 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 719 files belonging to 18 classes.\n",
      "Found 346 files belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../data/OpenAnimalTracks/cropped_imgs/train\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../data/OpenAnimalTracks/cropped_imgs/test\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")\n",
    "val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../data/OpenAnimalTracks/cropped_imgs/val\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

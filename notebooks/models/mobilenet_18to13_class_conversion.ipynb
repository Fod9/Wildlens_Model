{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet 18â†’13 Class Conversion\n",
    "\n",
    "This notebook converts the trained 18-class MobileNet model to a proper 13-class model by:\n",
    "1. Loading the original 18-class model\n",
    "2. Extracting the feature backbone\n",
    "3. Adding a new 13-class classification head\n",
    "4. Fine-tuning on 13-class data\n",
    "5. Creating the production model with correct preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# GPU setup\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"Keras: {keras.__version__}\")\n",
    "print(f\"Using device: {'GPU' if tf.config.list_physical_devices('GPU') else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original 18-class model\n",
    "original_model = keras.models.load_model(\"mobilnet_masterclass.keras\")\n",
    "\n",
    "original_model.summary()\n",
    "\n",
    "print(f\"\\nCurrent model :{original_model.layers[-1].units} output classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract backbone and create 13-class model\n",
    "dense_layers = [(i, layer) for i, layer in enumerate(original_model.layers) \n",
    "                if isinstance(layer, keras.layers.Dense)]\n",
    "\n",
    "backbone_end_idx = dense_layers[-2][0]\n",
    "backbone_end_layer = dense_layers[-2][1]\n",
    "\n",
    "# Rebuild backbone\n",
    "backbone_layers = original_model.layers[:backbone_end_idx + 1]\n",
    "new_backbone = keras.Sequential(name=\"backbone_13class\")\n",
    "\n",
    "# Copy each layer to preserve weights\n",
    "for i, layer in enumerate(backbone_layers):\n",
    "    config = layer.get_config()\n",
    "    weights = layer.get_weights()\n",
    "    \n",
    "    new_layer = layer.__class__.from_config(config)\n",
    "    new_backbone.add(new_layer)\n",
    "    \n",
    "    if weights:\n",
    "        if i == 0:\n",
    "            dummy_input = np.random.random((1, 224, 224, 3))\n",
    "            new_backbone(dummy_input)\n",
    "        new_layer.set_weights(weights)\n",
    "\n",
    "# Create 13-class model\n",
    "model_13class = keras.Sequential([\n",
    "    new_backbone,\n",
    "    keras.layers.Dense(13, activation=\"softmax\", name=\"classification_13class\")\n",
    "], name=\"mobilenet_13class\")\n",
    "\n",
    "# Build the model\n",
    "dummy_input = np.random.random((1, 224, 224, 3))\n",
    "_ = model_13class(dummy_input)\n",
    "\n",
    "print(f\"\\nNew model with {model_13class.output_shape} output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 13-class dataset and fine-tune\n",
    "print(\"Loading 13-class dataset...\")\n",
    "real_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../../data/dataset_no_oat_downsample\",\n",
    "    image_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "train_size = int(0.8 * len(real_ds))\n",
    "real_train_ds = real_ds.take(train_size)\n",
    "real_val_ds = real_ds.skip(train_size)\n",
    "\n",
    "data_dir = \"../../data/dataset_no_oat_downsample\"\n",
    "class_names = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "print(f\"Classes ({len(class_names)}): {class_names}\")\n",
    "\n",
    "model_13class.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history = model_13class.fit(\n",
    "    real_train_ds,\n",
    "    epochs=30,\n",
    "    validation_data=real_val_ds,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "val_loss, val_accuracy = model_13class.evaluate(real_val_ds, verbose=0)\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create production model with preprocessing\n",
    "\n",
    "production_model = keras.Sequential([\n",
    "    keras.layers.Resizing(224, 224, interpolation=\"bilinear\", name=\"resize_to_224\"),\n",
    "    # No Rescaling layer : model was trained on [0,255] pixel values\n",
    "    model_13class,\n",
    "], name=\"wildlens_13class_production\")\n",
    "\n",
    "production_model.summary()\n",
    "\n",
    "# Save models\n",
    "model_13class.save(\"mobilenet_13class_corrected.keras\")\n",
    "production_model.save(\"wildlens_multiclassifier.keras\")\n",
    "\n",
    "print(\"\\nModels saved:\")\n",
    "print(\"   - mobilenet_13class_corrected.keras (13-class model)\")\n",
    "print(\"   - wildlens_multiclassifier.keras (production model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick validation test\n",
    "\n",
    "# Simple inference function\n",
    "def predict_track(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_array = np.array(img, dtype=np.uint8)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    predictions = production_model.predict(img_array, verbose=0)\n",
    "    predicted_idx = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_idx]\n",
    "    predicted_class = class_names[predicted_idx]\n",
    "    \n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Test with a few sample images\n",
    "test_images = []\n",
    "for class_name in class_names[:3]:  # Test first 3 classes\n",
    "    class_dir = f\"../../data/dataset_no_oat_downsample/{class_name}\"\n",
    "    if os.path.exists(class_dir):\n",
    "        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        if images:\n",
    "            test_images.append(os.path.join(class_dir, images[0]))\n",
    "\n",
    "print(f\"\\nTesting {len(test_images)} sample images:\")\n",
    "correct = 0\n",
    "for img_path in test_images:\n",
    "    predicted_class, confidence = predict_track(img_path)\n",
    "    true_class = os.path.basename(os.path.dirname(img_path))\n",
    "    is_correct = predicted_class == true_class\n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "    \n",
    "    print(f\"{os.path.basename(img_path)}: {true_class} -> {predicted_class} ({confidence:.3f}) {'Correct' if is_correct else 'Incorrect'}\")\n",
    "\n",
    "print(f\"\\nResults: {correct}/{len(test_images)} correct ({correct/len(test_images)*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
